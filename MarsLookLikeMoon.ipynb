{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxLYVAZLHrq9"
   },
   "source": [
    "#  Extrapolation of CNN Trained on Mars Satellite Data to Classify Lunar Features\n",
    "### by Aniruddha Prasad and Andrew Hartnett\n",
    "\n",
    "The following notebook will train a Convolutional Neural Network (CNN) on satellite images taken of Mars from the HiRISE dataset. Afterwards, it will conduct transfer learning onto similar satellite images of Earth's Moon. The model is tested on its ability to classify the **geography(?)** of the Moon having trained on mostly if not entirely on images of Mars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g91PowrTJY8Z"
   },
   "source": [
    "## Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7Q6Up9gCJbUO"
   },
   "outputs": [],
   "source": [
    "# Import all required libraries and functions:\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import csv\n",
    "from tensorflow import keras\n",
    "from keras import utils, layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('PS') #prevent import error due to venv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "# Imports for dataset separation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Improve progress bar display\n",
    "import tqdm\n",
    "from tqdm import auto\n",
    "tqdm.tqdm = tqdm.auto.tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The way Neihusst Preprocesses their data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images = []\n",
    "data_labels = []\n",
    "rel_img_path = 'map-proj/' # add path of folder to image name for later loading\n",
    "\n",
    "# open up the labeled data file\n",
    "with open('labels-map-proj.txt') as labels:\n",
    "  for line in labels:\n",
    "    file_name, label = line.split(' ')\n",
    "    data_images.append(rel_img_path + file_name)\n",
    "    data_labels.append(int(label))\n",
    "\n",
    "# divide data into testing and training (total len 3820)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    data_images, data_labels, test_size=0.15, random_state=666)\n",
    "test_len = len(test_images)   # 573\n",
    "train_len = len(train_images) # 3247\n",
    "\n",
    "# label translations\n",
    "class_labels = ['other','crater','dark_dune','streak',\n",
    "                'bright_dune','impact','edge']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image paths into numpy matrices\n",
    "def parse_image(filename):\n",
    "  img_obj = Image.open(filename)\n",
    "  img = np.asarray(img_obj).astype(np.float32)\n",
    "  #normalize image to 0-1 range\n",
    "  img /= 255.0\n",
    "  return img\n",
    "\n",
    "train_images = np.array(list(map(parse_image, train_images)))\n",
    "test_images = np.array(list(map(parse_image, test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(label):\n",
    "  encoding = [0 for _ in range(len(class_labels))]\n",
    "  encoding[label] = 1\n",
    "  return np.array(encoding).astype(np.float32)\n",
    "\n",
    "train_labels = np.array(list(map(to_one_hot, train_labels)))\n",
    "test_labels = np.array(list(map(to_one_hot, test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5s4SiueJdS0"
   },
   "source": [
    "## Define and train the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of Performing image classifaction with the keras library:\n",
    "\n",
    "*https://www.tensorflow.org/tutorials/images/classification*\n",
    "\n",
    "The way the data is arranged in this example is that in a directory of all images, each class gets its own folder. This is how they are effectively labeled. This could be a way we could do it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xijbkS3HHpF6"
   },
   "outputs": [],
   "source": [
    "# Define the neural network, would be nice to show the use of GridSearchCV and a param_grid for optimization\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "# Compile the model:\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model:\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(train_ds, validation_data = val_ds, epochs=epochs)\n",
    "\n",
    "#Train_ds and val_ds is how the image data is stored. We need to store the data in a similar fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcVXcnFzKd4F"
   },
   "outputs": [],
   "source": [
    "# Print the best_params_ for GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpYf15ARKl9v"
   },
   "outputs": [],
   "source": [
    "# Evaluate the CNN on validation set\n",
    "\n",
    "# Make a plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rWPBmRjJg_N"
   },
   "source": [
    "## Evaluate the CNN on remaining Mars images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMNOpQyFJpZV"
   },
   "outputs": [],
   "source": [
    "# Evaluate the CNN on testing set\n",
    "\n",
    "# Make a plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJOcrcR3KyS8"
   },
   "source": [
    "#### Short response to our findings:\n",
    "Was the output expected? what did we do for optimizations? is it overfit/underfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sd9islKCJqR7"
   },
   "source": [
    "## Evaluate the CNN on Lunar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZIqycfwJsyl"
   },
   "outputs": [],
   "source": [
    "# Load Lunar images into a test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcD4UzddLPrB"
   },
   "outputs": [],
   "source": [
    "# Evaluate the CNN on Lunar set - we could use data augmentation to increase size of labeled images\n",
    "\n",
    "# Make a plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRjTKI3ULWfZ"
   },
   "source": [
    "#### Short response to our findings:\n",
    "Was the output expected? what did we do for optimizations? is it overfit/underfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXWTz801Jtan"
   },
   "source": [
    "## Perform transfer learning using a small set of Lunar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMaK6yVDJx19"
   },
   "outputs": [],
   "source": [
    "# Learn how to do transfer learning and do that here\n",
    "\n",
    "# Probably split the lunar images into training and test\n",
    "\n",
    "# Retrain CNN with Mars and some Lunar images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0B9_Ng0J0Cb"
   },
   "source": [
    "## Evaluate the transfer learning CNN on Lunar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyS-HxNvJ3r_"
   },
   "outputs": [],
   "source": [
    "# Evaluate the CNN on remaining Lunar set\n",
    "\n",
    "# Make a plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnBnbhI_J4K4"
   },
   "source": [
    "## Compare the results of before/after transfer learning for Lunar images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwWQuLdMLx49"
   },
   "source": [
    "This could probably be done in text, although a cool double-plot comparison could look good. Something like X: epochs, Y: accuracy with both before/after transfer learning models on the same plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKEq237YJ955"
   },
   "source": [
    "## Do something similar with Random Forest Classifier as a base, compare the two approaches based on their test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7F8p6aqKKnz"
   },
   "outputs": [],
   "source": [
    "# Same thing, just different model\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MarsLookLikeMoon.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
