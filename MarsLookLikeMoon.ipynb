{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxLYVAZLHrq9"
   },
   "source": [
    "#  Extrapolation of CNN Trained on Mars Satellite Data to Classify Lunar Features\n",
    "### by Aniruddha Prasad and Andrew Hartnett\n",
    "\n",
    "The following notebook will train a Convolutional Neural Network (CNN) on satellite images taken of Mars from the HiRISE dataset. Afterwards, it will conduct transfer learning onto similar satellite images of Earth's Moon. The model is tested on its ability to classify the **geography(?)** of the Moon having trained on mostly if not entirely on images of Mars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g91PowrTJY8Z"
   },
   "source": [
    "## Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7Q6Up9gCJbUO"
   },
   "outputs": [],
   "source": [
    "# Import all required libraries and functions:\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import csv\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The way Neihusst Preprocesses their data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images = []\n",
    "data_labels = []\n",
    "rel_img_path = 'map-proj/' # add path of folder to image name for later loading\n",
    "\n",
    "# open up the labeled data file\n",
    "with open('labels-map-proj.txt') as labels:\n",
    "  for line in labels:\n",
    "    file_name, label = line.split(' ')\n",
    "    data_images.append(rel_img_path + file_name)\n",
    "    data_labels.append(int(label))\n",
    "\n",
    "# divide data into testing and training (total len 3820)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    data_images, data_labels, test_size=0.15, random_state=666)\n",
    "test_len = len(test_images)   # 573\n",
    "train_len = len(train_images) # 3247\n",
    "\n",
    "# label translations\n",
    "class_labels = ['other','crater','dark_dune','streak',\n",
    "                'bright_dune','impact','edge']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image paths into numpy matrices\n",
    "def parse_image(filename):\n",
    "  img_obj = Image.open(filename)\n",
    "  img = np.asarray(img_obj).astype(np.float32)\n",
    "  #normalize image to 0-1 range\n",
    "  img /= 255.0\n",
    "  return img\n",
    "\n",
    "train_images = np.array(list(map(parse_image, train_images)))\n",
    "test_images = np.array(list(map(parse_image, test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(label):\n",
    "  encoding = [0 for _ in range(len(class_labels))]\n",
    "  encoding[label] = 1\n",
    "  return np.array(encoding).astype(np.float32)\n",
    "\n",
    "train_labels = np.array(list(map(to_one_hot, train_labels)))\n",
    "test_labels = np.array(list(map(to_one_hot, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gxWgqeEuGbXq"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11580/3673243374.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/content/drive/MyDrive/datasets/concrete_crack/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhirise_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Positive/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Need to store the images as 227x227 matrices in a larger array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Path to find HiRISE images at\n",
    "base_path='\"C:\\Users\\Andrew\\Documents\\Final-Project---ECE-697ML\"'\n",
    "\n",
    "# Width/height of the images\n",
    "size = 120\n",
    "\n",
    "# Load the hirise-map-proj-v3 folder into variables\n",
    "hirise_images = load_images(base_path + 'hirise-map-proj-v3/', size)\n",
    "images = np.array(hirise_images)\n",
    "\n",
    "# Need to store the images as 227x227 matrices in a larger array\n",
    "\n",
    "# If you want to load one image at a time, you can use the PIL libraries image\n",
    "# function and the np assaray function.\n",
    "\n",
    "# Below code is used to load images into a format for machine learning:\n",
    "\n",
    "\n",
    "# os.chdir('pictures')\n",
    "\n",
    "# files = tf.data.Dataset.list_files('*jpg') # Change to png if needed\n",
    "\n",
    "# def load_images(path):\n",
    "#     image = tf.io.read_file(path)\n",
    "#     image = tf.io.decode_jpeg(image)\n",
    "#     image = tf.image.convert_image_dtype(image, tf.float32) # optional\n",
    "#     image = tf.image.resize(image, (size, size))              # optional\n",
    "#     return image \n",
    "\n",
    "# ds = files.map(load_images(path)).batch(1)\n",
    "\n",
    "\n",
    "# Now you can store the array into cells using a for loop \n",
    "# img = Image.open('sample.png')\n",
    "# numpydata = asarray(img)\n",
    "\n",
    "# Translate the y values from label-map-proj-v3.txt using landmarks_map-proj-v3_classmap.csv\n",
    "\n",
    "\n",
    "# Print the shapes of each to check that we have 1 image for 1 classification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zxO5x-BHhn_"
   },
   "outputs": [],
   "source": [
    "# Split the images into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5s4SiueJdS0"
   },
   "source": [
    "## Define and train the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of Performing image classifaction with the keras library:\n",
    "\n",
    "*https://www.tensorflow.org/tutorials/images/classification*\n",
    "\n",
    "The way the data is arranged in this example is that in a directory of all images, each class gets its own folder. This is how they are effectively labeled. This could be a way we could do it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xijbkS3HHpF6"
   },
   "outputs": [],
   "source": [
    "# Define the neural network, would be nice to show the use of GridSearchCV and a param_grid for optimization\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "# Compile the model:\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model:\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(train_ds, validation_data = val_ds, epochs=epochs)\n",
    "\n",
    "#Train_ds and val_ds is how the image data is stored. We need to store the data in a similar fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcVXcnFzKd4F"
   },
   "outputs": [],
   "source": [
    "# Print the best_params_ for GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpYf15ARKl9v"
   },
   "outputs": [],
   "source": [
    "# Evaluate the CNN on validation set\n",
    "\n",
    "# Make a plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rWPBmRjJg_N"
   },
   "source": [
    "## Evaluate the CNN on remaining Mars images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMNOpQyFJpZV"
   },
   "outputs": [],
   "source": [
    "# Evaluate the CNN on testing set\n",
    "\n",
    "# Make a plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJOcrcR3KyS8"
   },
   "source": [
    "#### Short response to our findings:\n",
    "Was the output expected? what did we do for optimizations? is it overfit/underfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sd9islKCJqR7"
   },
   "source": [
    "## Evaluate the CNN on Lunar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZIqycfwJsyl"
   },
   "outputs": [],
   "source": [
    "# Load Lunar images into a test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcD4UzddLPrB"
   },
   "outputs": [],
   "source": [
    "# Evaluate the CNN on Lunar set - we could use data augmentation to increase size of labeled images\n",
    "\n",
    "# Make a plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRjTKI3ULWfZ"
   },
   "source": [
    "#### Short response to our findings:\n",
    "Was the output expected? what did we do for optimizations? is it overfit/underfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXWTz801Jtan"
   },
   "source": [
    "## Perform transfer learning using a small set of Lunar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMaK6yVDJx19"
   },
   "outputs": [],
   "source": [
    "# Learn how to do transfer learning and do that here\n",
    "\n",
    "# Probably split the lunar images into training and test\n",
    "\n",
    "# Retrain CNN with Mars and some Lunar images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0B9_Ng0J0Cb"
   },
   "source": [
    "## Evaluate the transfer learning CNN on Lunar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyS-HxNvJ3r_"
   },
   "outputs": [],
   "source": [
    "# Evaluate the CNN on remaining Lunar set\n",
    "\n",
    "# Make a plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnBnbhI_J4K4"
   },
   "source": [
    "## Compare the results of before/after transfer learning for Lunar images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwWQuLdMLx49"
   },
   "source": [
    "This could probably be done in text, although a cool double-plot comparison could look good. Something like X: epochs, Y: accuracy with both before/after transfer learning models on the same plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKEq237YJ955"
   },
   "source": [
    "## Do something similar with Random Forest Classifier as a base, compare the two approaches based on their test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7F8p6aqKKnz"
   },
   "outputs": [],
   "source": [
    "# Same thing, just different model\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MarsLookLikeMoon.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
