{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxLYVAZLHrq9"
   },
   "source": [
    "#  Comparison of CNN to Vision Transformer model trained on HiRISE Mars Satellite Images     (Feel free to change this)\n",
    "### by Aniruddha Prasad and Andrew Hartnett\n",
    "\n",
    "The following notebook will compare the accuracies of a Convolutional Neural Network (CNN) and Vision Transformer (ViT) trained on satellite images taken of Mars from the HiRISE dataset. The goal of this work is to determine whether or not a pre-trained ViT model, which has been seen used as the state-of-the-art for image classification in certain circumstances, will prove better when pre-trained on a significant size dataset and fine-tuned to this data. Then, we will train 3 version of each model with larger and larger subsets of the data to determine the trend in accuracy for each model. This will tell us which model will be best as more images are accumulated over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "1. Prepare the Training Data\n",
    "2. Define and Train the CNN - **WIP**\n",
    "3. Define and Train the Vision Transformer (ViT) - **WIP**\n",
    "4. Evaluate CNN vs ViT - **WIP**\n",
    "5. Retrain CNN and ViT on small, medium, and full HiRISE - **WIP**\n",
    "6. Compare three CNNs vs three ViTs - **WIP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g91PowrTJY8Z"
   },
   "source": [
    "## 1. Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tendorflow imports\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('PS') #prevent import error due to venv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "# Imports for dataset separation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Improve progress bar display\n",
    "import tqdm\n",
    "import tqdm.auto\n",
    "tqdm.tqdm = tqdm.auto.tqdm\n",
    "\n",
    "# Imports for CNN gridsearch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, make_scorer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Imports for comparing the performances of the models:\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The way Neihusst Preprocesses their data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images = []\n",
    "data_labels = []\n",
    "rel_img_path = 'hirise-map-proj-v3/map-proj/' # add path of folder to image name for later loading\n",
    "\n",
    "# open up the labeled data file\n",
    "with open('hirise-map-proj-v3/labels-map-proj.txt') as labels:\n",
    "  for line in labels:\n",
    "    file_name, label = line.split(' ')\n",
    "    data_images.append(rel_img_path + file_name)\n",
    "    data_labels.append(int(label))\n",
    "\n",
    "# divide data into testing and training (total len 3820)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    data_images, data_labels, test_size=0.15, random_state=666)\n",
    "test_len = len(test_images)   # 573\n",
    "train_len = len(train_images) # 3247\n",
    "\n",
    "# label translations\n",
    "class_labels = ['other','crater','dark_dune','streak',\n",
    "                'bright_dune','impact','edge']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3247\n"
     ]
    }
   ],
   "source": [
    "# Print length of training set (should be 3247)\n",
    "print(train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n"
     ]
    }
   ],
   "source": [
    "# Print length of testing set (should be 573)\n",
    "print(test_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image paths into numpy matrices\n",
    "def parse_image(filename):\n",
    "  img_obj = Image.open(filename)\n",
    "  img = np.asarray(img_obj).astype(np.float32)\n",
    "  #normalize image to 0-1 range\n",
    "  img /= 255.0\n",
    "  return img\n",
    "\n",
    "train_images = np.array(list(map(parse_image, train_images)))\n",
    "test_images = np.array(list(map(parse_image, test_images)))\n",
    "\n",
    "# Add 4th dimension to image arrays to allow for model.fit to take them as inputs\n",
    "train_images = np.reshape(train_images, (-1, 227, 227, 1))\n",
    "test_images = np.reshape(test_images, (-1, 227, 227, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227, 227, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that training images have been created into a 3D array of 3247 images of 227x227 pixels\n",
    "np.shape(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.4       ]\n",
      "  [0.4       ]\n",
      "  [0.40392157]\n",
      "  ...\n",
      "  [0.32156864]\n",
      "  [0.30980393]\n",
      "  [0.29803923]]\n",
      "\n",
      " [[0.4       ]\n",
      "  [0.4       ]\n",
      "  [0.4       ]\n",
      "  ...\n",
      "  [0.30588236]\n",
      "  [0.2901961 ]\n",
      "  [0.27058825]]\n",
      "\n",
      " [[0.4       ]\n",
      "  [0.4       ]\n",
      "  [0.39607844]\n",
      "  ...\n",
      "  [0.29803923]\n",
      "  [0.26666668]\n",
      "  [0.23921569]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.4117647 ]\n",
      "  [0.4117647 ]\n",
      "  [0.4117647 ]\n",
      "  ...\n",
      "  [0.654902  ]\n",
      "  [0.6862745 ]\n",
      "  [0.6784314 ]]\n",
      "\n",
      " [[0.40392157]\n",
      "  [0.40392157]\n",
      "  [0.40784314]\n",
      "  ...\n",
      "  [0.70980394]\n",
      "  [0.75686276]\n",
      "  [0.76862746]]\n",
      "\n",
      " [[0.4       ]\n",
      "  [0.4       ]\n",
      "  [0.4       ]\n",
      "  ...\n",
      "  [0.74509805]\n",
      "  [0.80784315]\n",
      "  [0.8352941 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(label):\n",
    "  encoding = [0 for _ in range(len(class_labels))]\n",
    "  encoding[label] = 1\n",
    "  return np.array(encoding).astype(np.float32)\n",
    "\n",
    "train_labels = np.array(list(map(to_one_hot, train_labels)))\n",
    "test_labels = np.array(list(map(to_one_hot, test_labels)))\n",
    "\n",
    "train_labels = np.reshape(train_labels, (-1, 7))\n",
    "test_labels = np.reshape(test_labels, (-1, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print one-hot encoding of labels (train_image[0] is classified as \"dark_dune\")\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5s4SiueJdS0"
   },
   "source": [
    "## 2. Define and Train the CNN - WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Source: https://github.com/niehusst/HiRISE-Net\n",
    "\n",
    "This project by **niehusst** on GitHub sought to emulate the HiRISENet model used in the \"Deep Mars\" paper. The CNN defined in his project provided us a base CNN to use which we tuned to improve the test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xijbkS3HHpF6"
   },
   "outputs": [],
   "source": [
    "# make a generator to train the model with\n",
    "generator = ImageDataGenerator(rotation_range=0, zoom_range=0,\n",
    "    width_shift_range=0, height_shift_range=0, shear_range=0,\n",
    "    horizontal_flip=False, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 227, 227, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 113, 113, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 113, 113, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               25690240  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 25,709,959\n",
      "Trainable params: 25,709,959\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###             BUILD SHAPE OF THE MODEL              ###\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
    "      input_shape=(227,227,1)),\n",
    "  tf.keras.layers.MaxPooling2D((2,2), strides=2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
    "  tf.keras.layers.MaxPooling2D((2,2), strides=2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(7, activation=tf.nn.softmax), # final layer with node for each classification\n",
    "])\n",
    "\n",
    "# specify loss and SGD functions\n",
    "model.compile(optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 102 steps\n",
      "Epoch 1/11\n",
      "102/102 [==============================] - 402s 4s/step - loss: 1.1024 - accuracy: 0.6883\n",
      "Epoch 2/11\n",
      "102/102 [==============================] - 412s 4s/step - loss: 0.6822 - accuracy: 0.7579\n",
      "Epoch 3/11\n",
      "102/102 [==============================] - 425s 4s/step - loss: 0.4960 - accuracy: 0.8300\n",
      "Epoch 4/11\n",
      "102/102 [==============================] - 445s 4s/step - loss: 0.3335 - accuracy: 0.8879\n",
      "Epoch 5/11\n",
      "102/102 [==============================] - 430s 4s/step - loss: 0.2436 - accuracy: 0.9202\n",
      "Epoch 6/11\n",
      "102/102 [==============================] - 1448s 14s/step - loss: 0.1697 - accuracy: 0.9446\n",
      "Epoch 7/11\n",
      "102/102 [==============================] - 499s 5s/step - loss: 0.1198 - accuracy: 0.9627\n",
      "Epoch 8/11\n",
      "102/102 [==============================] - 486s 5s/step - loss: 0.0780 - accuracy: 0.9726\n",
      "Epoch 9/11\n",
      "102/102 [==============================] - 1674s 16s/step - loss: 0.0573 - accuracy: 0.9837\n",
      "Epoch 10/11\n",
      "102/102 [==============================] - 410s 4s/step - loss: 0.0563 - accuracy: 0.9846\n",
      "Epoch 11/11\n",
      "102/102 [==============================] - 429s 4s/step - loss: 0.0236 - accuracy: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff1c7f93ed0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###                 TRAIN THE MODEL                   ###\n",
    "\n",
    "#specify training metadata\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# train the model on the training data\n",
    "num_epochs = 11\n",
    "model.fit(generator.flow(train_images, train_labels, batch_size=BATCH_SIZE), epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sd9islKCJqR7"
   },
   "source": [
    "## 3. Define and Train the Vision Transformer (ViT) - WIP\n",
    "Website used as a source: https://theaisummer.com/hugging-face-vit/\n",
    "\n",
    "Original code that required Linux for JAX and Flax: https://github.com/google-research/vision_transformer/blob/main/vit_jax_augreg.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hugsvision.dataio.VisionDataset import VisionDataset\n",
    "\n",
    "train, test, id2label, label2id = VisionDataset.fromImageFolder(\n",
    "    \"./hirise-map-proj-v3/data/\",\n",
    "    test_ratio   = 0.15,\n",
    "    balanced     = False,\n",
    "    augmentation = True,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_model = 'google/vit-base-patch16-224-in21k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hugsvision.nnet.VisionClassifierTrainer import VisionClassifierTrainer\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "model_name = \"HIRISE_20EPOCH\"\n",
    "\n",
    "trainer = VisionClassifierTrainer(\n",
    "    model_name   = model_name,\n",
    "    train        = train,\n",
    "    test         = test,\n",
    "    output_dir   = \"hirise-map-proj-v3/out/\",\n",
    "    max_epochs   = 5,\n",
    "    batch_size   = 12, # On RTX 2080 Ti\n",
    "    lr           = 2e-5,\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        huggingface_model,\n",
    "        num_labels = len(label2id),\n",
    "        label2id   = label2id,\n",
    "        id2label   = id2label\n",
    "    ),\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained(\n",
    "        huggingface_model,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(ref, hyp)\n",
    "labels = list(label2id.keys())\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 8}, fmt=\"\")\n",
    "plt.savefig(\"./hirise-map-proj-v3/out/\"+model_name+\"/conf_matrix_1.jpg\")\n",
    "\n",
    "print(\"Confusion Matrix saved to ./hirise-map-proj-v3/out/\"+model_name+\"/conf_matrix_1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate CNN vs ViT - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 37s 65ms/sample - loss: 1.6219 - accuracy: 0.7853\n",
      "Final loss was 1.1140381678236717.\n",
      "Accuracy of model was 0.7853403091430664\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the CNN - BEST IS 81% AFTER 5 EPOCHS\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(\"Final loss was {}.\\nAccuracy of model was {}\".format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the ViT\n",
    "ref, hyp = trainer.evaluate_f1_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ViT\n",
    "\n",
    "Produces an accuracy of 70.83% when pre-trained on \"vit-base-patch16-224-in21k\" at 5 epochs (map-proj and map-proj-v3)\n",
    "\n",
    "Produces an accuracy of 95.83% when pre-trained on \"vit-base-patch16-224-in21k\" at 20 epochs (map-proj and map-proj-v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRjTKI3ULWfZ"
   },
   "source": [
    "#### Short response to our findings:\n",
    "Was the output expected? what did we do for optimizations? is it overfit/underfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrain CNN and ViT on small, medium, and full HiRISE - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain 3 times each\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare three CNNs vs three ViTs - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate predictions for the test data using the CNN:\n",
    "cnn_label_pred = np.argmax(model.predict(test_images), axis=-1)\n",
    "# convert to one hot encoding to compare to the test labels\n",
    "cnn_label_pred = np.array(list(map(to_one_hot, cnn_label_pred)))\n",
    "# print a classification report to observe performance of the CNN\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # This was done because there was a warning with the f1-score that was breaking anything but didn't look presentable\n",
    "print(classification_report(test_labels,cnn_label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Code - Should not be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Data from map-proj-v3 : We need 7 folders named\n",
    "# for each class label with all of the images that apply to that class\n",
    "\n",
    "# import os\n",
    "# import os.path\n",
    "# from shutil import copy2\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # label translations\n",
    "# class_labels = ['other','crater','dark_dune','streak',\n",
    "#                 'bright_dune','impact','swiss_cheese','spider']\n",
    "\n",
    "# img_in = \"C:/Users/Andrew/Documents/Final-Project---ECE-697ML/hirise-map-proj-v3/map-proj/\"\n",
    "# img_out = \"C:/Users/Andrew/Documents/Final-Project---ECE-697ML/hirise-map-proj-v/data/\"\n",
    "\n",
    "# with open('hirise-map-proj-v3/labels-map-proj.txt') as labels:\n",
    "#   for line in labels:\n",
    "#     file_name, label = line.split(' ')\n",
    "    \n",
    "#     # Change label number into class label\n",
    "#     class_temp = class_labels[int(label)]\n",
    "    \n",
    "#     # Update path to copy the image to\n",
    "#     path_out_full = img_out + class_temp\n",
    "    \n",
    "#     # Get the full path of the image\n",
    "#     path_in_full = img_in + file_name\n",
    "    \n",
    "#     # Check if the input image exist\n",
    "#     if not os.path.isfile(path_in_full):\n",
    "#         continue\n",
    "        \n",
    "#     # Check if the output dir of the label exist\n",
    "#     if not os.path.isdir(path_out_full):\n",
    "#         os.mkdir(path_out_full)\n",
    "\n",
    "#     # Copy the image\n",
    "#     copy2(path_in_full, path_out_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Data from map-proj : We need 8 folders named\n",
    "# for each class label with all of the images that apply to that class\n",
    "\n",
    "# import os\n",
    "# import os.path\n",
    "# from shutil import copy2\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # label translations\n",
    "# class_labels = ['other','crater','dark_dune','streak',\n",
    "#                 'bright_dune','impact','swiss_cheese','spider']\n",
    "\n",
    "# img_in = \"C:/Users/Andrew/Documents/Final-Project---ECE-697ML/hirise-map-proj-v3/map-proj-v3/\"\n",
    "# img_out = \"C:/Users/Andrew/Documents/Final-Project---ECE-697ML/hirise-map-proj-v3/data/\"\n",
    "\n",
    "# with open('hirise-map-proj-v3/labels-map-proj-v3.txt') as labels:\n",
    "#   for line in labels:\n",
    "#     file_name, label = line.split(' ')\n",
    "    \n",
    "#     # Change label number into class label\n",
    "#     class_temp = class_labels[int(label)]\n",
    "    \n",
    "#     # Update path to copy the image to\n",
    "#     path_out_full = img_out + class_temp\n",
    "    \n",
    "#     # Get the full path of the image\n",
    "#     path_in_full = img_in + file_name\n",
    "    \n",
    "#     # Check if the input image exist\n",
    "#     if not os.path.isfile(path_in_full):\n",
    "#         continue\n",
    "        \n",
    "#     # Check if the output dir of the label exist\n",
    "#     if not os.path.isdir(path_out_full):\n",
    "#         os.mkdir(path_out_full)\n",
    "\n",
    "#     # Copy the image\n",
    "#     copy2(path_in_full, path_out_full)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MarsLookLikeMoon.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "0fc39ccd5bae79e0dc0f4ab744cc141bd552c15f15784503cee4845a428cfb74"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
