{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxLYVAZLHrq9"
   },
   "source": [
    "#  Comparison of CNN to Vision Transformer model trained on HiRISE Mars Satellite Images     (Feel free to change this)\n",
    "### by Aniruddha Prasad and Andrew Hartnett\n",
    "\n",
    "The following notebook will compare the accuracies of a Convolutional Neural Network (CNN) and Vision Transformer (ViT) trained on satellite images taken of Mars from the HiRISE dataset. The goal of this work is to determine whether or not a pre-trained ViT model, which has been seen used as the state-of-the-art for image classification in certain circumstances, will prove better when pre-trained on a significant size dataset and fine-tuned to this data. Then, we will train 3 version of each model with larger and larger subsets of the data to determine the trend in accuracy for each model. This will tell us which model will be best as more images are accumulated over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "1. Prepare the Training Data\n",
    "2. Define and Train the CNN - **WIP**\n",
    "3. Define and Train the Vision Transformer (ViT) - **WIP**\n",
    "4. Evaluate CNN vs ViT - **WIP**\n",
    "5. Retrain CNN and ViT on small, medium, and full HiRISE - **WIP**\n",
    "6. Compare three CNNs vs three ViTs - **WIP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g91PowrTJY8Z"
   },
   "source": [
    "## 1. Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Tendorflow imports\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('PS') #prevent import error due to venv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "# Imports for dataset separation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Improve progress bar display\n",
    "import tqdm\n",
    "import tqdm.auto\n",
    "tqdm.tqdm = tqdm.auto.tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The way Neihusst Preprocesses their data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images = []\n",
    "data_labels = []\n",
    "rel_img_path = 'hirise-map-proj-v3/map-proj/' # add path of folder to image name for later loading\n",
    "\n",
    "# open up the labeled data file\n",
    "with open('hirise-map-proj-v3/labels-map-proj.txt') as labels:\n",
    "  for line in labels:\n",
    "    file_name, label = line.split(' ')\n",
    "    data_images.append(rel_img_path + file_name)\n",
    "    data_labels.append(int(label))\n",
    "\n",
    "# divide data into testing and training (total len 3820)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    data_images, data_labels, test_size=0.15, random_state=666)\n",
    "test_len = len(test_images)   # 573\n",
    "train_len = len(train_images) # 3247\n",
    "\n",
    "# label translations\n",
    "class_labels = ['other','crater','dark_dune','streak',\n",
    "                'bright_dune','impact','edge']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3247\n"
     ]
    }
   ],
   "source": [
    "# Print length of training set (should be 3247)\n",
    "print(train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n"
     ]
    }
   ],
   "source": [
    "# Print length of testing set (should be 573)\n",
    "print(test_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image paths into numpy matrices\n",
    "def parse_image(filename):\n",
    "  img_obj = Image.open(filename)\n",
    "  img = np.asarray(img_obj).astype(np.float32)\n",
    "  #normalize image to 0-1 range\n",
    "  img /= 255.0\n",
    "  return img\n",
    "\n",
    "train_images = np.array(list(map(parse_image, train_images)))\n",
    "test_images = np.array(list(map(parse_image, test_images)))\n",
    "\n",
    "# Add 4th dimension to image arrays to allow for model.fit to take them as inputs\n",
    "train_images = np.reshape(train_images, (-1, 227, 227, 1))\n",
    "test_images = np.reshape(test_images, (-1, 227, 227, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227, 227, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that training images have been created into a 3D array of 3247 images of 227x227 pixels\n",
    "np.shape(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.4       ]\n",
      "  [0.4       ]\n",
      "  [0.40392157]\n",
      "  ...\n",
      "  [0.32156864]\n",
      "  [0.30980393]\n",
      "  [0.29803923]]\n",
      "\n",
      " [[0.4       ]\n",
      "  [0.4       ]\n",
      "  [0.4       ]\n",
      "  ...\n",
      "  [0.30588236]\n",
      "  [0.2901961 ]\n",
      "  [0.27058825]]\n",
      "\n",
      " [[0.4       ]\n",
      "  [0.4       ]\n",
      "  [0.39607844]\n",
      "  ...\n",
      "  [0.29803923]\n",
      "  [0.26666668]\n",
      "  [0.23921569]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.4117647 ]\n",
      "  [0.4117647 ]\n",
      "  [0.4117647 ]\n",
      "  ...\n",
      "  [0.654902  ]\n",
      "  [0.6862745 ]\n",
      "  [0.6784314 ]]\n",
      "\n",
      " [[0.40392157]\n",
      "  [0.40392157]\n",
      "  [0.40784314]\n",
      "  ...\n",
      "  [0.70980394]\n",
      "  [0.75686276]\n",
      "  [0.76862746]]\n",
      "\n",
      " [[0.4       ]\n",
      "  [0.4       ]\n",
      "  [0.4       ]\n",
      "  ...\n",
      "  [0.74509805]\n",
      "  [0.80784315]\n",
      "  [0.8352941 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(label):\n",
    "  encoding = [0 for _ in range(len(class_labels))]\n",
    "  encoding[label] = 1\n",
    "  return np.array(encoding).astype(np.float32)\n",
    "\n",
    "train_labels = np.array(list(map(to_one_hot, train_labels)))\n",
    "test_labels = np.array(list(map(to_one_hot, test_labels)))\n",
    "\n",
    "train_labels = np.reshape(train_labels, (-1, 7))\n",
    "test_labels = np.reshape(test_labels, (-1, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print one-hot encoding of labels (train_image[0] is classified as \"dark_dune\")\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5s4SiueJdS0"
   },
   "source": [
    "## 2. Define and Train the CNN - WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Source: https://github.com/niehusst/HiRISE-Net\n",
    "\n",
    "This project by **niehusst** on GitHub sought to emulate the HiRISENet model used in the \"Deep Mars\" paper. The CNN defined in his project provided us a base CNN to use which we tuned to improve the test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xijbkS3HHpF6"
   },
   "outputs": [],
   "source": [
    "# make a generator to train the model with\n",
    "generator = ImageDataGenerator(rotation_range=0, zoom_range=0,\n",
    "    width_shift_range=0, height_shift_range=0, shear_range=0,\n",
    "    horizontal_flip=False, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 11:07:50.976498: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-08 11:07:50.987043: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 227, 227, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 113, 113, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 113, 113, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               25690240  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 25,709,959\n",
      "Trainable params: 25,709,959\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###             BUILD SHAPE OF THE MODEL              ###\n",
    "\n",
    "# increase kernel size and stride??\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
    "      input_shape=(227,227,1)),\n",
    "  tf.keras.layers.MaxPooling2D((2,2), strides=2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
    "  tf.keras.layers.MaxPooling2D((2,2), strides=2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(7, activation=tf.nn.softmax), # final layer with node for each classification\n",
    "])\n",
    "\n",
    "# specify loss and SGD functions\n",
    "model.compile(optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 102 steps\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 421s 4s/step - loss: 1.0530 - accuracy: 0.6963\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 376s 4s/step - loss: 0.6482 - accuracy: 0.7712\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 368s 4s/step - loss: 0.4751 - accuracy: 0.8285\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 387s 4s/step - loss: 0.3276 - accuracy: 0.8814\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 392s 4s/step - loss: 0.2224 - accuracy: 0.9295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbff977e950>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###                 TRAIN THE MODEL                   ###\n",
    "\n",
    "#specify training metadata\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# train the model on the training data\n",
    "num_epochs = 5\n",
    "model.fit(generator.flow(train_images, train_labels, batch_size=BATCH_SIZE), epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sd9islKCJqR7"
   },
   "source": [
    "## 3. Define and Train the Vision Transformer (ViT) - WIP\n",
    "Website used as a source: https://theaisummer.com/hugging-face-vit/\n",
    "\n",
    "Original code that required Linux for JAX and Flax: https://github.com/google-research/vision_transformer/blob/main/vit_jax_augreg.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hugsvision.dataio.VisionDataset import VisionDataset\n",
    "\n",
    "train, test, id2label, label2id = VisionDataset.fromImageFolder(\n",
    "    \"./hirise-map-proj-v3/data/\",\n",
    "    test_ratio   = 0.15,\n",
    "    balanced     = False,\n",
    "    augmentation = True,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_model = 'google/vit-base-patch16-224-in21k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hugsvision.nnet.VisionClassifierTrainer import VisionClassifierTrainer\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "model_name = \"HIRISE_20EPOCH\"\n",
    "\n",
    "trainer = VisionClassifierTrainer(\n",
    "    model_name   = model_name,\n",
    "    train        = train,\n",
    "    test         = test,\n",
    "    output_dir   = \"hirise-map-proj-v3/out/\",\n",
    "    max_epochs   = 5,\n",
    "    batch_size   = 12, # On RTX 2080 Ti\n",
    "    lr           = 2e-5,\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        huggingface_model,\n",
    "        num_labels = len(label2id),\n",
    "        label2id   = label2id,\n",
    "        id2label   = id2label\n",
    "    ),\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained(\n",
    "        huggingface_model,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(ref, hyp)\n",
    "labels = list(label2id.keys())\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 8}, fmt=\"\")\n",
    "plt.savefig(\"./hirise-map-proj-v3/out/\"+model_name+\"/conf_matrix_1.jpg\")\n",
    "\n",
    "print(\"Confusion Matrix saved to ./hirise-map-proj-v3/out/\"+model_name+\"/conf_matrix_1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate CNN vs ViT - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 36s 63ms/sample - loss: 0.8884 - accuracy: 0.8063\n",
      "Final loss was 0.7035678427464883.\n",
      "Accuracy of model was 0.8062826991081238\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the CNN - BEST IS 81% AFTER 5 EPOCHS\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(\"Final loss was {}.\\nAccuracy of model was {}\".format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search on CNN to determine best params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the ViT\n",
    "ref, hyp = trainer.evaluate_f1_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ViT\n",
    "\n",
    "Produces an accuracy of 70.83% when pre-trained on \"vit-base-patch16-224-in21k\" at 5 epochs (map-proj and map-proj-v3)\n",
    "\n",
    "Produces an accuracy of 95.83% when pre-trained on \"vit-base-patch16-224-in21k\" at 20 epochs (map-proj and map-proj-v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRjTKI3ULWfZ"
   },
   "source": [
    "#### Short response to our findings:\n",
    "Was the output expected? what did we do for optimizations? is it overfit/underfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrain CNN and ViT on small, medium, and full HiRISE - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain 3 times each\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare three CNNs vs three ViTs - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for the clout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Code - Should not be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Data from map-proj-v3 : We need 7 folders named\n",
    "# for each class label with all of the images that apply to that class\n",
    "\n",
    "# import os\n",
    "# import os.path\n",
    "# from shutil import copy2\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # label translations\n",
    "# class_labels = ['other','crater','dark_dune','streak',\n",
    "#                 'bright_dune','impact','swiss_cheese','spider']\n",
    "\n",
    "# img_in = \"C:/Users/Andrew/Documents/Final-Project---ECE-697ML/hirise-map-proj-v3/map-proj/\"\n",
    "# img_out = \"C:/Users/Andrew/Documents/Final-Project---ECE-697ML/hirise-map-proj-v/data/\"\n",
    "\n",
    "# with open('hirise-map-proj-v3/labels-map-proj.txt') as labels:\n",
    "#   for line in labels:\n",
    "#     file_name, label = line.split(' ')\n",
    "    \n",
    "#     # Change label number into class label\n",
    "#     class_temp = class_labels[int(label)]\n",
    "    \n",
    "#     # Update path to copy the image to\n",
    "#     path_out_full = img_out + class_temp\n",
    "    \n",
    "#     # Get the full path of the image\n",
    "#     path_in_full = img_in + file_name\n",
    "    \n",
    "#     # Check if the input image exist\n",
    "#     if not os.path.isfile(path_in_full):\n",
    "#         continue\n",
    "        \n",
    "#     # Check if the output dir of the label exist\n",
    "#     if not os.path.isdir(path_out_full):\n",
    "#         os.mkdir(path_out_full)\n",
    "\n",
    "#     # Copy the image\n",
    "#     copy2(path_in_full, path_out_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Data from map-proj : We need 8 folders named\n",
    "# for each class label with all of the images that apply to that class\n",
    "\n",
    "# import os\n",
    "# import os.path\n",
    "# from shutil import copy2\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # label translations\n",
    "# class_labels = ['other','crater','dark_dune','streak',\n",
    "#                 'bright_dune','impact','swiss_cheese','spider']\n",
    "\n",
    "# img_in = \"C:/Users/Andrew/Documents/Final-Project---ECE-697ML/hirise-map-proj-v3/map-proj-v3/\"\n",
    "# img_out = \"C:/Users/Andrew/Documents/Final-Project---ECE-697ML/hirise-map-proj-v3/data/\"\n",
    "\n",
    "# with open('hirise-map-proj-v3/labels-map-proj-v3.txt') as labels:\n",
    "#   for line in labels:\n",
    "#     file_name, label = line.split(' ')\n",
    "    \n",
    "#     # Change label number into class label\n",
    "#     class_temp = class_labels[int(label)]\n",
    "    \n",
    "#     # Update path to copy the image to\n",
    "#     path_out_full = img_out + class_temp\n",
    "    \n",
    "#     # Get the full path of the image\n",
    "#     path_in_full = img_in + file_name\n",
    "    \n",
    "#     # Check if the input image exist\n",
    "#     if not os.path.isfile(path_in_full):\n",
    "#         continue\n",
    "        \n",
    "#     # Check if the output dir of the label exist\n",
    "#     if not os.path.isdir(path_out_full):\n",
    "#         os.mkdir(path_out_full)\n",
    "\n",
    "#     # Copy the image\n",
    "#     copy2(path_in_full, path_out_full)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MarsLookLikeMoon.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "0fc39ccd5bae79e0dc0f4ab744cc141bd552c15f15784503cee4845a428cfb74"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
